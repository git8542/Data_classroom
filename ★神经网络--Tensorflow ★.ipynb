{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.40295255] [ 0.82534146]\n",
      "20 [-0.07075184] [ 0.39448124]\n",
      "40 [ 0.05201474] [ 0.32655147]\n",
      "60 [ 0.08651501] [ 0.30746159]\n",
      "80 [ 0.0962104] [ 0.30209687]\n",
      "100 [ 0.09893503] [ 0.30058929]\n",
      "120 [ 0.0997007] [ 0.30016562]\n",
      "140 [ 0.09991589] [ 0.30004653]\n",
      "160 [ 0.09997637] [ 0.3000131]\n",
      "180 [ 0.09999337] [ 0.30000368]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data *.1 + .3\n",
    "\n",
    "# create tensorflow structure start\n",
    "Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "biases = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "y = Weights * x_data + biases\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "# create tensorflow structure end\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    if step %20 == 0:\n",
    "        print(step, sess.run(Weights), sess.run(biases))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n",
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3,3]])\n",
    "matrix2 = tf.constant([[2],\n",
    "                      [2]])\n",
    "product = tf.matmul(matrix1, matrix2) # matrix multiply  np.dot(m1,m2)\n",
    "\n",
    "# method 1\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "\n",
    "# method 2  recommed method\n",
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print(result2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "one = tf.Variable(1)\n",
    "new_value = tf.add(state,one)\n",
    "\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict={input1:[7], input2:[2]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    \n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) +0.1)\n",
    "    \n",
    "    Wx_plus_biases = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_biases\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_biases)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.linspace(-1, 1, 300)[:,np.newaxis]\n",
    "noise = np.random.normal(0,0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "xs = tf.placeholder(tf.float32,[None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25074ee2160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-a61f3b729f25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprediction_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r-\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mpause\u001b[1;34m(interval)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;31m# No on-screen figure is active, so sleep() is all we need.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(.1).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(x_data, y_data)\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={xs:x_data, ys:y_data})\n",
    "    if i % 50:\n",
    "        #print(sess.run(loss, feed_dict={xs:x_data, ys:y_data}))\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction, feed_dict={xs:x_data})\n",
    "        lines = ax.plot(x_data, prediction_value, \"r-\", lw=5)\n",
    "        plt.pause(0.1)\n",
    "\n",
    "print(prediction_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument <function global_variables_initializer at 0x000002506ABB0730> has invalid type <class 'function'>, must be a string or Tensor. (Can not convert a function into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 267\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    268\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2583\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2584\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2672\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[1;32m-> 2673\u001b[1;33m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[0;32m   2674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a function into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-c833d787c0c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"logs/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m--> 984\u001b[1;33m         self._graph, fetches, feed_dict_string, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \"\"\"\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    269\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    270\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    272\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument <function global_variables_initializer at 0x000002506ABB0730> has invalid type <class 'function'>, must be a string or Tensor. (Can not convert a function into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.name_scope(\"input\"):\n",
    "    \n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name=\"x_in\")\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name=\"y_in\")\n",
    "    \n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    \n",
    "    with tf.name_scope(\"layer\"):\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]),name=\"W\")\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + .1)\n",
    "        with tf.name_scope(\"Wx_plus_b\"):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b)\n",
    "        return outputs\n",
    "\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))\n",
    "\n",
    "with tf.name_scope(\"train_step\"):\n",
    "    train_step = tf.train.GradientDescentOptimizer(.1).minimize(loss)\n",
    "    \n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "sess.run(tf.global_variables_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "0.122\n",
      "0.6405\n",
      "0.7339\n",
      "0.7824\n",
      "0.8047\n",
      "0.8223\n",
      "0.8338\n",
      "0.8425\n",
      "0.844\n",
      "0.8527\n",
      "0.8587\n",
      "0.861\n",
      "0.8629\n",
      "0.8652\n",
      "0.8624\n",
      "0.867\n",
      "0.8685\n",
      "0.8763\n",
      "0.098\n",
      "0.098\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None,):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b,)\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "prediction = add_layer(xs, 784, 10,  activation_function=tf.nn.softmax)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None,):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b,)\n",
    "    return outputs\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "xs = tf.placeholder(tf.float32, [None, 64])\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add  output layer\n",
    "l1 = add_layer(xs, 64, 50, activation_function=tf.nn.tanh)\n",
    "prediction = add_layer(l1, 50, 10,activation_function=tf.nn.softmax )\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(- tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))\n",
    "tf.summary.scalar(\"loss\", cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(.6).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "#summary writer goes in here\n",
    "train_writer = tf.summary.FileWriter(\"logs/train\", sess.graph)\n",
    "test_writer =  tf.summary.FileWriter(\"logs/test\", sess.graph)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(500):\n",
    "    \n",
    "    sess.run(train_step, feed_dict={xs: X_train, ys:y_train, keep_prob:0.5})\n",
    "    if i % 50 ==0:\n",
    "        # record loss\n",
    "        train_result = sess.run(merged,feed_dict={xs:X_train, ys:y_train, keep_prob:1})\n",
    "        test_result = sess.run(merged, feed_dict={xs:X_test, ys:y_test, keep_prob: 1})\n",
    "        train_writer.add_summary(train_result, i)\n",
    "        test_writer.add_summary(test_result, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
